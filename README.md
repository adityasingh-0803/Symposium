# Symposium: Talking to Virtual Minds

## 🧠 Project Overview

**Symposium: Talking to Virtual Minds** is an AI-powered, emotion-aware conversational experience featuring embodied avatars of visionary leaders across domains like space, design, and medicine. Users engage in **one-on-one conversations**, where each AI persona responds dynamically to the user's selected emotion — complete with expressive speech, lip-sync animation, and intelligent background transitions.

Built using a fusion of **Conversational AI**, **Text-to-Speech**, **Generative Visuals**, and **Unity avatars**, Symposium reimagines how we interact with intelligent systems through immersive storytelling.

---

## 🎥 Project Demo

🔗 **[Watch the Demo Video (60–90s)](https://drive.google.com/file/d/1253jno2u23covNzBAOvY9_V8qYdhKO1m/view?usp=sharing)**  
🕹️ A complete walkthrough of the immersive experience, from emotion selection to avatar response and real-time background changes.

> *(Replace the above link with your actual hosted video — YouTube, Drive, or embedded player.)*

---

## 🎯 Key Features

- 🎭 Emotion-Driven Dialogue with GPT
- 👤 Embodied AI Leaders (Cooper, Elena Sparks, Dr. Aanya Verma)
- 🎧 Realistic Voice via ElevenLabs
- 🌌 Dynamic AI Backgrounds triggered by topic
- 🧠 Full Conversational Pipeline from emotion → avatar response

---

## 🧩 Technology Stack

| Component             | Tools / Models Used                          |
|-----------------------|----------------------------------------------|
| Natural Language Gen  | GPT-4 / Claude                               |
| Text-to-Speech (TTS)  | ElevenLabs / Replica Studios                 |
| Image Generation      | Midjourney / DALL·E                          |
| Avatar Creation       | ReadyPlayerMe / Mixamo                       |
| Lip Sync              | SALSA LipSync / Oculus LipSync              |
| Background Switching  | Unity Timeline + GPT theme segmentation     |
| Audio Mixing          | Unity Audio Mixer / Audacity                |

---

## 👤 AI Leaders

| Name               | Company            | Field         | Tagline                             |
|--------------------|--------------------|---------------|--------------------------------------|
| **Cooper**         | AstroCore          | Space AI      | "Guiding humanity beyond stars."     |
| **Elena Sparks**   | DesigNext AI       | Creative AI   | "Design for everyone, intelligently."|
| **Dr. Aanya Verma**| NeuroPulse AI      | Medical AI    | "Healing at the speed of thought."   |

---

## ⚙️ How It Works

1. **User selects an emotion** (e.g., hopeful, sad, curious).
2. GPT generates an **emotion-matched speech** for a chosen AI leader.
3. ElevenLabs produces the **spoken voice** with tone control.
4. Unity avatar plays the voice, **synchronized with lip movement**.
5. Backgrounds change dynamically, powered by GPT-extracted themes.

---


---

## 🚀 Future Work

- Real-time input via Whisper + GPT + TTS pipeline
- Emotion detection via facial expression / voice tone
- Multi-agent group conversation mode
- Memory-based persistent avatars
- Explainable AI dialogue (ethical alignment questions)

---

## 👥 Team & Roles

- **Conversational AI & Prompts** – [Your Name]
- **Unity & Scene Integration** – [Teammate Name]
- **Voice & Audio Mixing** – [Teammate Name]
- **Avatar Design & Lip Sync** – [Teammate Name]

---

## 📝 Submission Info

- **Challenge:** AI Video Generation Challenge – Visionary Leaders Edition  
- **Project Title:** *Symposium: Talking to Virtual Minds*  
- **Duration:** 60–90 seconds  
- **Category:** AI + Conversational Interfaces + Embodied Agents  

---

## 📬 Contact
Team name: SimLink


